{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from metpy.plots import StationPlot\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from siphon.simplewebservice.iastate import IAStateUpperAir\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Station Information\n",
    "\n",
    "A helper function for obtaining radiosonde station information (e.g., latitude/longitude) requried to plot data obtained from each station. Original code by github user sgdecker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import numpy as np\n",
    "\n",
    "def station_info(stid):\n",
    "    r\"\"\"Provide information about weather stations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    stid: str or iterable object containing strs\n",
    "         The ICAO or IATA code(s) for which station information is requested.\n",
    "    with_units: bool\n",
    "         Whether to include units for values that have them. Default True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    info: dict\n",
    "         Information about the station(s) within a dictionary with these keys:\n",
    "             'state': Two-character ID of the state/province where the station is located,\n",
    "                       if applicable\n",
    "             'name': The name of the station\n",
    "             'lat': The latitude of the station [deg]\n",
    "             'lon': The longitude of the station [deg]\n",
    "             'elevation': The elevation of the station [m]\n",
    "             'country': Two-character ID of the country where the station is located\n",
    "    \n",
    "    Modified code from Steven Decker, Rutgers University\n",
    "\n",
    "    \"\"\"\n",
    "    # Provide a helper function for later usage\n",
    "    def str2latlon(s):\n",
    "        deg = float(s[:3])\n",
    "        mn = float(s[-3:-1])\n",
    "        if s[-1] == 'S' or s[-1] == 'W':\n",
    "            deg = -deg\n",
    "            mn = -mn\n",
    "        res = deg + mn / 60.\n",
    "        return res\n",
    "\n",
    "    # Various constants describing the underlying data\n",
    "    url = 'https://www.aviationweather.gov/docs/metar/stations.txt'\n",
    "    #file = 'stations.txt'\n",
    "    state_bnds = slice(0, 2)\n",
    "    name_bnds = slice(3, 19)\n",
    "    icao_bnds = slice(20, 24)\n",
    "    iata_bnds = slice(26, 29)\n",
    "    lat_bnds = slice(39, 45)\n",
    "    lon_bnds = slice(47, 54)\n",
    "    z_bnds = slice(55, 59)\n",
    "    cntry_bnds = slice(81, 83)\n",
    "\n",
    "    # Generalize to any number of IDs\n",
    "    if isinstance(stid, str):\n",
    "        stid = [stid]\n",
    "\n",
    "    # Get the station dataset\n",
    "    infile = urllib.request.urlopen(url)\n",
    "    data = infile.readlines()\n",
    "#     infile = open(file, 'rb')\n",
    "#     data = infile.readlines()\n",
    "\n",
    "    state = []\n",
    "    name = []\n",
    "    lat = []\n",
    "    lon = []\n",
    "    z = []\n",
    "    cntry = []\n",
    "    \n",
    "    for s in stid:\n",
    "        s = s.upper()\n",
    "        for line_bytes in data:\n",
    "            line = line_bytes.decode('UTF-8')\n",
    "            icao = line[icao_bnds]\n",
    "            iata = line[iata_bnds]\n",
    "            if len(s) == 3 and s in iata or len(s) == 4 and s in icao:\n",
    "                state.append(line[state_bnds].strip())\n",
    "                name.append(line[name_bnds].strip())\n",
    "                lat.append(str2latlon(line[lat_bnds]))\n",
    "                lon.append(str2latlon(line[lon_bnds]))\n",
    "                z.append(float(line[z_bnds]))\n",
    "                cntry.append(line[cntry_bnds])\n",
    "                \n",
    "                break\n",
    "        else:\n",
    "             #raise ValueError('Station {} not found!'.format(s))\n",
    "            state.append('NA')\n",
    "            name.append('NA')\n",
    "            lat.append(np.nan)\n",
    "            lon.append(np.nan)\n",
    "            z.append(np.nan)\n",
    "            cntry.append('NA')\n",
    "\n",
    "    res = {'state': np.array(state), 'name': np.array(name), 'lat': np.array(lat), 'lon': np.array(lon), 'elevation': np.array(z),\n",
    "           'country': np.array(cntry), 'units': {'lat': 'deg', 'lon': 'deg', 'z': 'm'}}\n",
    "    infile.close()\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "import pyproj\n",
    "\n",
    "geod = pyproj.Geod(ellps='sphere')\n",
    "\n",
    "def near_neighbor(xi, yi, xk, yk, phi):\n",
    "    grid = np.zeros((len(yi),len(xi)))\n",
    "    for e in range(len(xi)):\n",
    "        for f in range(len(yi)):\n",
    "            dum_dist = 10000000.\n",
    "            for g in range(len(xk)):\n",
    "                #dist = (((xk[g]-xi[e])**2) + ((yk[g]-yi[f])**2))**(0.5)\n",
    "                _, _, dist = geod.inv(xk[g], yk[g], xi[e], yi[f])\n",
    "                if (dist <= dum_dist):\n",
    "                    dum_dist = dist\n",
    "                    dum_phi = phi[g]\n",
    "                elif (dist == dum_dist):\n",
    "                    dum_phi = (dum_phi + phi[g])/2.\n",
    "            grid[f,e] = dum_phi\n",
    "    return gaussian_filter(grid, sigma=2)\n",
    "\n",
    "def barnes_guess(x_i, y_i, x_k, y_k, phi_0, roi):\n",
    "    grid = np.zeros((len(y_i),len(x_i)))\n",
    "    # Loop through the grid and update the initial grid with the observations\n",
    "    for l in range(len(x_i)):\n",
    "        for m in range(len(y_i)):\n",
    "            sum_weight = 0.\n",
    "            num_weight = 0.\n",
    "            weight = 0.\n",
    "            for p in range(len(phi_0)): # Loop for the observations\n",
    "                # Determining the distance between the observation and a grid point\n",
    "                #rad2 = ((x_k[p]-x_i[l])**2 + (y_k[p]-y_i[m])**2)**(1/2)\n",
    "                _, _, rad2 = geod.inv(x_k[p], y_k[p], x_i[l], y_i[m])\n",
    "                weight = np.exp(-(rad2**2)/(roi**2))\n",
    "                sum_weight+=weight\n",
    "                weight_phi = weight * phi_0[p] # \n",
    "                num_weight+=weight_phi\n",
    "                #print(rad2, weight)\n",
    "            grid[m,l] = num_weight/sum_weight\n",
    "    return gaussian_filter(grid, sigma=2)\n",
    "\n",
    "def cressman(x_i, y_i, x_k, y_k, phi_0, guess_field):\n",
    "    # Estimate of grid at Obs points\n",
    "    h = np.zeros(len(phi_0)).astype('float')\n",
    "\n",
    "    # Assimilated Grid\n",
    "    grid = np.zeros((len(y_i),len(x_i)))\n",
    "    #print(grid.shape)\n",
    "\n",
    "    # Begin the Cressman Scheme, doing three passes with Radius of Influence (roi)\n",
    "    # of 80, 50, and 40 grid points\n",
    "    for i in [1,2]:\n",
    "        if (i == 1):\n",
    "            roi = (1500*1000)**2.\n",
    "        elif (i == 2):\n",
    "            roi = (900*1000.)**2.\n",
    "        else:\n",
    "            roi = 5.**2.\n",
    "\n",
    "            # Calculating the values of the grid at the observation points through simple linear interpolation\n",
    "        for p in range(len(phi_0)):\n",
    "            #print(y_k[p]==np.nan, x_k[p])\n",
    "            if (np.int64(y_k[p]) in y_i.astype('int64')) & ((np.int64(x_k[p]) in x_i.astype('int64'))):\n",
    "                a = np.where(y_i.astype('int64') == np.int64(y_k[p]))[0][0]\n",
    "                a2 = np.abs(y_i[a] - (y_k[p]))\n",
    "                b = np.where(x_i.astype('int64') == np.int64(x_k[p]))[0][0]\n",
    "                b2 = np.abs(x_i[b] - (x_k[p]))\n",
    "                #print(a-1, a2, b-1, b2)\n",
    "                h[p] = (((guess_field[a,b]*(1-b2)+guess_field[a,b+1]*b2))*(1-a2) +\n",
    "                        ((guess_field[a-1,b]*(1-b2)+guess_field[a-1,b+1]*b2))*(a2))\n",
    "            else:\n",
    "                h[p] = phi_0[p]\n",
    "\n",
    "    # Loop through the grid and update the initial grid with the observations\n",
    "        for l in range(len(x_i)):\n",
    "            for m in range(len(y_i)):\n",
    "                sum_weight = 0.\n",
    "                num_weight = 0.\n",
    "                weight     = 0.\n",
    "                for p in range(len(phi_0)): # Loop for the observations\n",
    "                    # Determining the distance between the observation and a grid point\n",
    "                    #rad2 = ((x_k[p]-x_i[l])**2 + (y_k[p]-y_i[m])**2)\n",
    "                    _, _, rad2 = geod.inv(x_k[p], y_k[p], x_i[l], y_i[m])\n",
    "                    rad2 = rad2**2\n",
    "                    #print(dist2)\n",
    "                    if (rad2 <= roi):\n",
    "                        weight = (roi - rad2)/(roi + rad2) # Setting the weight if within the roi\n",
    "                    else:\n",
    "                        weight = 0. # Setting the weight of the ob to zero if outside the roi\n",
    "                    sum_weight+=weight\n",
    "                    weight_phi = weight * (phi_0[p] - h[p]) # \n",
    "                    num_weight+=weight_phi\n",
    "                if sum_weight > 0:\n",
    "                    grid[m,l] = guess_field[m,l] + (num_weight/sum_weight) # Updating the grid\n",
    "                else:\n",
    "                    grid[m,l] = guess_field[m,l]\n",
    "\n",
    "\n",
    "\n",
    "        guess_field = grid   # Saving the grid to use in the next iteration\n",
    "    return grid\n",
    "\n",
    "def barnes(x_i, y_i, x_k, y_k, phi_0, guess_field):\n",
    "    # Estimate of grid at Obs points\n",
    "    h = np.zeros(len(phi_0)).astype('float')\n",
    "\n",
    "    # Assimilated Grid\n",
    "    grid = np.zeros((len(y_i),len(x_i)))\n",
    "\n",
    "    # Begin the Cressman Scheme, doing three passes with Radius of Influence (roi)\n",
    "    # of 80, 50, and 40 grid points\n",
    "    roi = 1000*1000\n",
    "    for i in [1,2]:\n",
    "        if (i == 1):\n",
    "            gamma = 1\n",
    "        elif (i == 2):\n",
    "            gamma = 0.33\n",
    "\n",
    "        # Calculating the values of the grid at the observation points through simple linear interpolation\n",
    "        for p in range(len(phi_0)):\n",
    "            #print(np.int(y_k[p]) in y_i.astype('int'))\n",
    "            if (np.int64(y_k[p]) in y_i.astype('int64')) & ((np.int64(x_k[p]) in x_i.astype('int64'))):\n",
    "                #print('got here')\n",
    "                a = np.where(y_i.astype('int64') == np.int64(y_k[p]))[0][0]\n",
    "                a2 = np.abs(y_i[a] - (y_k[p]))\n",
    "                b = np.where(x_i.astype('int64') == np.int64(x_k[p]))[0][0]\n",
    "                b2 = np.abs(x_i[b] - (x_k[p]))\n",
    "                h[p] = (((guess_field[a,b]*(1-b2)+guess_field[a,b+1]*b2))*(1-a2) +\n",
    "                        ((guess_field[a-1,b]*(1-b2)+guess_field[a-1,b+1]*b2))*(a2))\n",
    "            else:\n",
    "                h[p] = phi_0[p]\n",
    "        #print(h)\n",
    "\n",
    "        # Loop through the grid and update the initial grid with the observations\n",
    "        for l in range(len(x_i)):\n",
    "            for m in range(len(y_i)):\n",
    "                sum_weight = 0.\n",
    "                num_weight = 0.\n",
    "                weight = 0.\n",
    "                for p in range(len(phi_0)): # Loop for the observations\n",
    "                    # Determining the distance between the observation and a grid point\n",
    "                    #rad2 = ((x_k[p]-x_i[l])**2 + (y_k[p]-y_i[m])**2)**(1/2)\n",
    "                    _, _, rad2 = geod.inv(x_k[p], y_k[p], x_i[l], y_i[m])\n",
    "                    weight = np.exp(-1*(rad2**2)/(gamma*(roi**2)))\n",
    "                    sum_weight+=weight\n",
    "                    weight_phi = weight * (phi_0[p] - h[p]) # \n",
    "                    num_weight+=weight_phi\n",
    "                #print(num_weight, sum_weight)\n",
    "                if sum_weight > 0:\n",
    "                    grid[m,l] = guess_field[m,l] + (num_weight/sum_weight) # Updating the grid\n",
    "                else:\n",
    "                    grid[m,l] = guess_field[m,l]\n",
    "\n",
    "\n",
    "\n",
    "        guess_field = grid   # Saving the grid to use in the next iteration\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set date to do analysis\n",
    "date = datetime(2017, 12, 9, 12)\n",
    "\n",
    "# Request data using Siphon request for data from Iowa State Archive\n",
    "data = IAStateUpperAir.request_all_data(date)\n",
    "\n",
    "# Set level\n",
    "level = 500\n",
    "\n",
    "# Create subset of all data for a given level\n",
    "data_subset = data.pressure == level\n",
    "df = data[data_subset]\n",
    "\n",
    "# Get station lat/lon from look-up file; add to Dataframe\n",
    "stn_info = station_info(list(df.station.values))\n",
    "df.insert(10, 'latitude', stn_info['lat'])\n",
    "df.insert(11, 'longitude', stn_info['lon'])\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = 360 + df.longitude.values\n",
    "lat = df.latitude.values\n",
    "hght_500 = df.height.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up geographic region\n",
    "LLLon = -140.\n",
    "LLLat = 19.\n",
    "URLon = -50.\n",
    "URLat = 70\n",
    "\n",
    "#ds = xr.open_dataset(f'http://www.ncei.noaa.gov/thredds/dodsC/model-gfs-g4-anl-files-old/'\n",
    "#                     f'{date:%Y%m}/{date:%Y%m%d}/gfsanl_4_{date:%Y%m%d}_{date:%H}00_000.grb2')\n",
    "\n",
    "ds = xr.open_dataset('/archive/courses/nwp/nwp_notebooks/gfsanl_3_20171209_1200_000.nc').metpy.parse_cf()\n",
    "\n",
    "gfs_hght_500 = ds.Geopotential_height.metpy.sel(time=date,\n",
    "                                                #vertical=500 * units.hPa,\n",
    "                                                lon=slice(360+LLLon, 360+URLon),\n",
    "                                                lat=slice(URLat, LLLat)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(FG_type):\n",
    "    lons = gfs_hght_500.lon.values\n",
    "    #lons[lons > 180] = lons - 360\n",
    "    lats = gfs_hght_500.lat.values\n",
    "    clons, clats = np.meshgrid(lons, lats)\n",
    "    \n",
    "    if FG_type == 'gfs':\n",
    "        # Get First Guess field from 6 hour forecast of GFS\n",
    "        ds_first_guess = xr.open_dataset('/archive/courses/nwp/nwp_notebooksgfs_3_20171209_0000_012.nc')\n",
    "        date_first_guess = date - timedelta(hours=12)\n",
    "        #ds_first_guess = xr.open_dataset(f'http://www.ncei.noaa.gov/thredds/dodsC/model-gfs-g3-anl-files-old/'\n",
    "        #                                 f'{date_first_guess:%Y%m}/{date_first_guess:%Y%m%d}/gfsanl_3_{date_first_guess:%Y%m%d}_'\n",
    "        #                                 f'{date_first_guess:%H}00_006.grb').metpy.parse_cf()\n",
    "\n",
    "        FG_hght_500 = ds_first_guess.Geopotential_height.metpy.sel(time=date,\n",
    "                                                                   #vertical=500 * units.hPa,\n",
    "                                                                   lon=slice(360+LLLon, 360+URLon),\n",
    "                                                                   lat=slice(URLat, LLLat)).squeeze()\n",
    "\n",
    "        FG = FG_hght_500.values\n",
    "        #FG_vtimes = FG_hght_500.time.values.astype('datetime64[ms]').astype('O')\n",
    "        FG_vtimes = date\n",
    "        #FG_vtimes = num2date(FG_time[:],units=FG_time.units)\n",
    "        #FG_hght_500 = data_gfs_first_guess.variables['Geopotential_height'][0,0,:,:]\n",
    "        #FG = FG_hght_500[iULat:iLLat,iLLon:iULon]\n",
    "        FG_title = 'GFS Fcst'\n",
    "    elif FG_type == 'NN':\n",
    "        FG = near_neighbor(lons,lats,lon,lat,hght_500)\n",
    "        FG_title = 'Nearest Neighbor'\n",
    "    # Set firstguess field for Cressman Scheme\n",
    "    # Use the Nearest Neighbor approach to initially fill the grid\n",
    "    elif FG_type == 'barnes':\n",
    "        FG = barnes_guess(lons,lats,lon,lat,hght_500,5e5)\n",
    "        FG_title = 'Barnes'\n",
    "    \n",
    "    # Generate Analyzed Fields with Cressman and Barnes\n",
    "    cress_hght_500 = cressman(lons,lats,lon,lat,hght_500,FG)\n",
    "    barnes_hght_500 = barnes(lons,lats,lon,lat,hght_500,FG)\n",
    "\n",
    "    print(\"First Guess Field: {}\".format(FG_type))\n",
    "    print(\"First Guess Error: {:.2f}\".format(np.average(gfs_hght_500.values-FG)))\n",
    "    print(\"Average Cressman Analysis Error: {:.2f}\".format(np.average(gfs_hght_500.values-cress_hght_500)))\n",
    "    print(\"Average Barnes Analysis Error: {:.2f}\".format(np.average(gfs_hght_500.values-barnes_hght_500)))\n",
    "\n",
    "    plotcrs = ccrs.PlateCarree()\n",
    "\n",
    "    fig = plt.figure(1,figsize=(20,15))\n",
    "    ax = fig.add_subplot(211,projection=plotcrs,label='top')\n",
    "\n",
    "    ax.set_extent([-130, -65, 20, 50])\n",
    "    ax.coastlines('50m')\n",
    "\n",
    "    ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='black', linewidth=0.5)\n",
    "    # Set up station plotting using only every third element from arrays for plotting\n",
    "    stationplot = StationPlot(ax, lon, lat, transform=ccrs.PlateCarree(), fontsize=12, clip_on=True)\n",
    "    stationplot.plot_parameter('C', hght_500)\n",
    "\n",
    "    cs = ax.contour(clons,clats,cress_hght_500,np.arange(0,7000,60),colors='r',linestyles='dashed')\n",
    "    plt.clabel(cs,fmt='%d')\n",
    "    cs3 = ax.contour(clons,clats,gfs_hght_500,np.arange(0,7000,60),colors='k')\n",
    "    plt.clabel(cs3,fmt='%d')\n",
    "\n",
    "    plt.title('500-hPa Geopotential Heights (Actual Analysis - black; Cressman Analysis - red)',loc='left')\n",
    "    plt.title(date, loc='right')\n",
    "\n",
    "    ax2 = fig.add_subplot(212, projection=plotcrs,label='bottom')\n",
    "    ax2.set_extent([-130, -65, 20, 50])\n",
    "    ax2.coastlines('50m')\n",
    "    ax2.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='black', linewidth=0.5)\n",
    "    # Set up station plotting using only every third element from arrays for plotting\n",
    "    stationplot = StationPlot(ax2, lon, lat, transform=ccrs.PlateCarree(), fontsize=12, clip_on=True)\n",
    "    stationplot.plot_parameter('C', hght_500)\n",
    "\n",
    "    cs2 = ax2.contour(clons,clats,barnes_hght_500,np.arange(0,7000,60),colors='b',linestyles='dotted')\n",
    "    plt.clabel(cs2,fmt='%d')\n",
    "    cs4 = ax2.contour(clons,clats,gfs_hght_500,np.arange(0,7000,60),colors='k')\n",
    "    plt.clabel(cs4,fmt='%d')\n",
    "    \n",
    "    plt.title('500-hPa Geopotential Heights (Actual Analysis - black; Barnes Analysis - blue)',loc='left')\n",
    "    plt.title(date, loc='right')\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, widgets\n",
    "\n",
    "interact(plot, FG_type = widgets.Dropdown(options={'GFS Fcst':'gfs','Nearest Neighbor':'NN','Barnes':'barnes'},\n",
    "                                          description='First Guess: '));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
